{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere  #LLM used for the development of the application\n",
    "from langchain_cohere import ChatCohere\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser\n",
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from fastapi import FastAPI, Request, HTTPException, Form\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate #for creating prompts with few-shot examples\n",
    "from langchain.prompts.prompt import PromptTemplate #for formatting the few-shot examples\n",
    "from langchain.prompts import FewShotChatMessagePromptTemplate\n",
    "from langchain.schema import HumanMessage, AIMessage, SystemMessage\n",
    "import json\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts import FewShotPromptTemplate\n",
    "from langchain_cohere import ChatCohere\n",
    "from langchain.output_parsers import ResponseSchema, StructuredOutputParser\n",
    "import psycopg2 #type: ignore\n",
    "import json\n",
    "\n",
    "load_dotenv()\n",
    "cohere_api_key = os.getenv(\"COHERE_TRIAL_API_KEY\")\n",
    "DB_CONFIG = {\n",
    "    \"user\": os.getenv(\"DB_USER\"),\n",
    "    \"password\": os.getenv(\"DB_PASSWORD\"),\n",
    "    \"host\": os.getenv(\"DB_HOST\"),\n",
    "    \"port\": os.getenv(\"DB_PORT\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_db_connection():\n",
    "    conn = psycopg2.connect(\n",
    "        user=DB_CONFIG[\"user\"],\n",
    "        password=DB_CONFIG[\"password\"],\n",
    "        host=DB_CONFIG[\"host\"],\n",
    "        port=DB_CONFIG[\"port\"],\n",
    "    )\n",
    "    return conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Convierte las preguntas y respuestas en un dataframe de python\n",
    "def db_get_questions():\n",
    "    conn = get_db_connection()\n",
    "    cursor = conn.cursor()\n",
    "    # query = ''' SELECT * FROM respuestas_usuarios '''\n",
    "    query = '''\n",
    "    SELECT pr.id_pregunta, pr.usuario, pr.contenido as pregunta_contenido, pr.categoria,\n",
    "    rs.contenido as respuesta_contenido, rs.id_respuesta, rs.id_pregunta, pr.activa FROM preguntas as pr\n",
    "    LEFT JOIN respuestas as rs on pr.id_pregunta = rs.id_pregunta\n",
    "    '''\n",
    "    # cursor.fetchall()\n",
    "    preguntas = pd.read_sql(query,conn)\n",
    "    print(cursor)\n",
    "    conn.close()\n",
    "    return preguntas\n",
    "preguntas = db_get_questions()\n",
    "preguntas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def db_user_context(id_sesion):\n",
    "    conn = get_db_connection()\n",
    "    cursor = conn.cursor()\n",
    "    # query = ''' SELECT * FROM respuestas_usuarios '''\n",
    "    cursor.execute('''\n",
    "        SELECT *\n",
    "        FROM respuestas_usuarios\n",
    "        WHERE id_sesion = %s\n",
    "        ORDER BY id_respuesta_usuario DESC LIMIT 1\n",
    "        ''', (id_sesion,))\n",
    "    desc = cursor.description\n",
    "    column_names = [col[0] for col in desc]\n",
    "    data = [dict(zip(column_names, row))  \n",
    "            for row in cursor.fetchall()]\n",
    "    conn.close()\n",
    "    return data[0]\n",
    "info_user= db_user_context(\"prueba_raul_limpiador\")\n",
    "info_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoria = \"divulgacion\"\n",
    "tipo_usuario = \"usuario\"\n",
    "df_preguntas = db_get_questions()\n",
    "df_preguntas['respuesta_contenido'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preguntas = db_get_questions()\n",
    "lista_preguntas= df_preguntas[(df_preguntas['categoria']==categoria) & (df_preguntas['usuario']==tipo_usuario) & (df_preguntas['activa']==True)]['pregunta_contenido'].unique().tolist()\n",
    "lista_respuestas = df_preguntas['respuesta_contenido'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_preguntas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_limpiador(id_sesion, categoria):\n",
    "\n",
    "    ### Sacamos contexto del usuario y las preguntas activas, antes de tocar por el LLM.\n",
    "    info_user= db_user_context(id_sesion)\n",
    "    id_respuesta_usuario=info_user['id_respuesta_usuario']\n",
    "    direccion_ip=info_user['direccion_ip']\n",
    "    tipo_usuario=info_user['tipo_usuario']\n",
    "    municipio=info_user['municipio']\n",
    "    ccaa=info_user['ccaa']\n",
    "    conocer_felgtbi=info_user['conocer_felgtbi']\n",
    "    data_date=info_user['data_date']\n",
    "    vih_usuario=info_user['vih_usuario']\n",
    "    vih_diagnostico=info_user['vih_diagnostico']\n",
    "    vih_tratamiento=info_user['vih_tratamiento']\n",
    "    us_edad=info_user['us_edad']\n",
    "    us_pais_origen=info_user['us_pais_origen']\n",
    "    us_genero=info_user['us_genero']\n",
    "    us_orientacion=info_user['us_orientacion']\n",
    "    us_situacion_afectiva=info_user['us_situacion_afectiva']\n",
    "    us_hablado=info_user['us_hablado']\n",
    "    pro_ambito=info_user['pro_ambito']\n",
    "    pro_especialidad=info_user['pro_especialidad']\n",
    "    pro_vih_profesional=info_user['pro_vih_profesional']\n",
    "\n",
    "    ### Preguntas\n",
    "    df_preguntas = db_get_questions()\n",
    "    preguntas_raw = df_preguntas[(df_preguntas['categoria']==categoria) & (df_preguntas['usuario']==tipo_usuario) & (df_preguntas['activa']==True)]['pregunta_contenido'].unique().tolist()\n",
    "    dict_preguntas_raw = {}\n",
    "    for i, pregunta in enumerate(preguntas_raw):\n",
    "        dict_preguntas_raw[i] = pregunta\n",
    "    dict_preguntas_raw\n",
    "\n",
    "    ### LLM\n",
    "    cohere_api_key = os.getenv(\"COHERE_TRIAL_API_KEY\")\n",
    "    llm = ChatCohere(cohere_api_key=cohere_api_key, temperature=0,model='command-r')\n",
    "\n",
    "    ### Response Schema para parser\n",
    "    response_schemas = [\n",
    "        ResponseSchema(name=\"diccionario_preguntas\", description= '''Preguntas finales, en formato diccionario de Python. La clave es el índice\n",
    "                       de la pregunta original, y el valor la pregunta filtrada. Ejemplo: 0:(pregunta1), 1:(pregunta2)'''),\n",
    "        ResponseSchema(name=\"message\", description=\"Explica de forma muy concisa por qué has excluido o incluido cada pregunta.\")\n",
    "    ]\n",
    "    output_parser = JsonOutputParser() \n",
    "\n",
    "    ### Template y ejecución\n",
    "    template = ChatPromptTemplate([\n",
    "        (\"system\", ''' Recibes una lista de preguntas en {preguntas}. Tu misión es filtrar esas preguntas en función del contexto que\n",
    "         conozcas del usuario. Pregunta sobre el embarazo sólo a tipo Mujer, o mujer cis género, y pregunta sobre la próstata sólo a tipo Hombre, u hombre cis género.\n",
    "        Si el usuario no tiene vih, elimina del listado todas las preguntas relativas al vih, bajo ninguna\n",
    "         circunstancia debes preguntar sobre el vih si el usuario no tiene vih. Sólo debes preguntar sobre el vih si el usuario nos confirma que tiene vih.\n",
    "        NUNCA, en ningún caso modifiques el texto de las preguntas. Sólo quitarás según consideres dado el contexto del usuario, pero NUNCA variarás su contenido.\n",
    "         Siempre escribirás \"vih\" (siempre en minúsculas, nunca en mayúsculas), ya que estamos desetigmatizando sobre la enfermedad.\n",
    "         Devuelve exactamente un JSON con dos claves: \n",
    "        - \"diccionario_preguntas\": Las preguntas finales como un diccionario de Python. La clave de la pregunta debe coincidir con el índice del listado de preguntas en {preguntas},\n",
    "         mientras que el valor será el texto de la pregunta.\n",
    "        - \"message\": Respuesta al usuario por parte del bot, explicando de forma detallada por qué has excluido o incluido cada pregunta.\n",
    "        NUNCA, NUNCA, incluyas texto adicional fuera del JSON.\n",
    "         '''),\n",
    "        (\"human\", '''Soy tipo de usuario {tipo_usuario}.  Vivo en {municipio} en la comunidad {ccaa}. Tengo {us_edad} años y nací en {us_pais_origen}.\n",
    "         Mi género es {us_genero} y mi orientación sexual es {us_orientacion}. Sobre mi situación afectiva, {us_situacion_afectiva}.\n",
    "         {us_hablado} he hablado sobre si tengo vih con mi entorno. A la pregunta de si tengo vih, la respuesta es {vih_usuario}, y, en caso de tenerlo, me dieron\n",
    "         el diagnóstico hace {vih_diagnostico}, y si sigo tratamiento es desde hace {vih_tratamiento}. Si soy tipo de usuario \"profesional\",\n",
    "        mi ámbito es {pro_ambito}, mi especialidad {pro_especialidad} y {pro_vih_profesional} he tratado a un afectado por vih.\n",
    "          ''')],\n",
    "        partial_variables={\"format_instructions\": output_parser.get_format_instructions()}\n",
    "        )\n",
    "    prompt_value = template.invoke({\"preguntas\":preguntas_raw,\"tipo_usuario\":tipo_usuario,\"municipio\":municipio, \"ccaa\":ccaa, \"conocer_felgtbi\":conocer_felgtbi, \"vih_usuario\":vih_usuario,\n",
    "                                    \"vih_diagnostico\":vih_diagnostico, \"vih_tratamiento\":vih_tratamiento, \"us_edad\": us_edad, \"us_pais_origen\":us_genero,\n",
    "                                    \"us_genero\":us_genero,\"us_orientacion\":us_orientacion, \"us_situacion_afectiva\": us_situacion_afectiva,\n",
    "                                    \"us_hablado\":us_hablado,\"pro_ambito\":pro_ambito,\"pro_especialidad\":pro_especialidad,\n",
    "                                    \"pro_vih_profesional\":pro_vih_profesional})\n",
    "    \n",
    "    print(dict_preguntas_raw)\n",
    "    print(us_genero)\n",
    "    print(vih_usuario)\n",
    "    response = llm.invoke(prompt_value)\n",
    "    print(response.content)\n",
    "    parsed_output = output_parser.parse(response.content)\n",
    "    \n",
    "\n",
    "    return parsed_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "preguntas = llm_limpiador('prueba_raul_limpiador', 'divulgacion')\n",
    "dict_preg_resp = {}\n",
    "for pregunta in preguntas['diccionario_preguntas'].keys():\n",
    "    resp_list = df_preguntas[df_preguntas[\"pregunta_contenido\"] == pregunta][\"respuesta_contenido\"].tolist()\n",
    "    dict_preg_resp[pregunta] = resp_list\n",
    "dict_preg_resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "preguntas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_preg_resp = {}\n",
    "for pregunta in preguntas['diccionario_preguntas'].keys():\n",
    "    resp_list = df_preguntas[df_preguntas[\"pregunta_contenido\"] == pregunta][\"respuesta_contenido\"].tolist()\n",
    "    dict_preg_resp[pregunta] = resp_list\n",
    "dict_preg_resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "preguntas_raw = df_preguntas[(df_preguntas['categoria']==\"divulgacion\") & (df_preguntas['usuario']==\"usuario\") & (df_preguntas['activa']==True)]['pregunta_contenido'].unique()\n",
    "preguntas_raw\n",
    "dict_preguntas_raw = {}\n",
    "for i, pregunta in enumerate(preguntas_raw):\n",
    "    dict_preguntas_raw[i] = pregunta\n",
    "dict_preguntas_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo con Álex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Ejemplo de Álex\n",
    "def llm_limpiador(id_sesion, categoria):\n",
    "    # Obtener contexto del usuario\n",
    "    info_user = db_user_context(id_sesion)\n",
    "    tipo_usuario = info_user['tipo_usuario']\n",
    "    municipio = info_user['municipio']\n",
    "    ccaa = info_user['ccaa']\n",
    "    vih_usuario = info_user['vih_usuario']\n",
    "    us_edad = info_user['us_edad']\n",
    "    us_pais_origen = info_user['us_pais_origen']\n",
    "    us_genero = info_user['us_genero']\n",
    "    us_orientacion = info_user['us_orientacion']\n",
    "    us_situacion_afectiva = info_user['us_situacion_afectiva']\n",
    "    us_hablado = info_user['us_hablado']\n",
    "    pro_ambito = info_user['pro_ambito']\n",
    "    pro_especialidad = info_user['pro_especialidad']\n",
    "    pro_vih_profesional = info_user['pro_vih_profesional']\n",
    "\n",
    "    # Obtener preguntas activas\n",
    "    df_preguntas = db_get_questions()\n",
    "    preguntas_unicas = df_preguntas[\n",
    "        (df_preguntas['categoria'] == categoria) &\n",
    "        (df_preguntas['usuario'] == tipo_usuario) &\n",
    "        (df_preguntas['activa'] == True)\n",
    "    ][['pregunta_contenido','id_pregunta']].drop_duplicates()\n",
    "    lista_preguntas = preguntas_unicas['pregunta_contenido'].tolist()\n",
    "    lista_ids = preguntas_unicas['id_pregunta'].iloc[:,0].tolist()\n",
    "    dict_preguntas = {}\n",
    "    for i in range(len(lista_preguntas)):\n",
    "        dict_preguntas[lista_ids[i]] = lista_preguntas[i]\n",
    "    dict_preguntas\n",
    "\n",
    "    # Configuración del LLM\n",
    "    cohere_api_key = os.getenv(\"COHERE_TRIAL_API_KEY\")\n",
    "    llm = ChatCohere(cohere_api_key=cohere_api_key, temperature=0, model='command-r')\n",
    "\n",
    "    # Template del prompt\n",
    "    prompt = f\"\"\"\n",
    "    Recibes un diccionario de preguntas: {dict_preguntas}. La clave es el ID de la pregunta, y el valor es el texto de la pregunta.\n",
    "    Tu tarea es filtrar las preguntas de acuerdo con el contexto del usuario, siguiendo las siguientes reglas:\n",
    "\n",
    "    1. **Filtrado por VIH**:\n",
    "    - Si el usuario **NO tiene vih**, elimina todas las preguntas relacionadas con padecer dicha enfermedad.\n",
    "\n",
    "    2. **Filtrado por género**:\n",
    "\n",
    "        - **Género masculino**: Si el género del usuario es **masculino**, elimina preguntas que no sean relevantes para este género. Por ejemplo, si una pregunta está relacionada con aspectos específicos de la biología femenina (como embarazo, periodo, etc), elimínala. Es decir, solo mantén preguntas que sean pertinentes a la biología o situaciones de los hombres.\n",
    "\n",
    "        - **Género femenino**: Si el género del usuario es **femenino**, elimina preguntas que no sean relevantes para este género. Por ejemplo, si una pregunta está relacionada con aspectos específicos de la biología masculina (como próstata), elimínala. Es decir, solo mantén preguntas que sean pertinentes a la biología o situaciones de las mujeres.\n",
    "\n",
    "        - **Género no binaria**: Si el género del usuario es **no binario**, elimina preguntas que se refieran de manera exclusiva a biología o situaciones de los géneros masculinos o femeninos. Este género no se asocia con los aspectos tradicionales de los géneros binarios, por lo que solo se deben incluir preguntas de carácter general o que no dependan del género biológico.\n",
    "\n",
    "        - **Prefiero no decirlo**: Si el usuario seleccionó **prefiero no decirlo** como género, elimina preguntas que estén asociadas con un género específico, ya que no se puede asumir el género del usuario. Solo incluye preguntas que no dependan de un género específico.\n",
    "\n",
    "    **Importante**: No modifiques el texto de las preguntas. Solo elimina las preguntas según las reglas mencionadas. Nunca debes modificar el contenido de las preguntas, solo eliminarlas si no son relevantes según el contexto.\n",
    "\n",
    "    **Importante**: No escribirás VIH en mayúsculas en ningún caso ya que estamos desestigmatizando dicha enfermedad.\n",
    "\n",
    "    Información del usuario:\n",
    "    Tipo: {tipo_usuario}, Municipio: {municipio}, CCAA: {ccaa}, Edad: {us_edad}, País de origen: {us_pais_origen},\n",
    "    Género: {us_genero}, Orientación: {us_orientacion}, Situación afectiva: {us_situacion_afectiva}, Ha hablado sobre vih: {us_hablado},\n",
    "    Tiene vih: {vih_usuario}, Profesional (ámbito: {pro_ambito}, especialidad: {pro_especialidad}, experiencia con vih: {pro_vih_profesional}).\n",
    "\n",
    "    Devuelve un diccionario en Python con las preguntas filtradas, en este formato:\n",
    "    {{\n",
    "        \"preguntas_filtradas\": {{ id de la pregunta original: \"texto de la pregunta\" }},\n",
    "        \"message\": \"Explicación de por qué se incluyeron/excluyeron las preguntas.\"\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    # Invocar el modelo\n",
    "    response = llm.invoke(prompt)\n",
    "    print(\"Respuesta del modelo:\", response.content)\n",
    "\n",
    "    # Procesar la respuesta como un diccionario\n",
    "    try:\n",
    "        result = eval(response.content.strip())\n",
    "    except (SyntaxError, ValueError) as e:\n",
    "        print(f\"Error procesando la respuesta: {e}\")\n",
    "        result = {\n",
    "            \"preguntas_filtradas\": {},\n",
    "            \"message\": \"Error al procesar la respuesta del modelo. Verifica el prompt o el formato de salida.\"\n",
    "        }\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "preguntas = llm_limpiador('prueba_raul_limpiador', 'divulgacion')\n",
    "\n",
    "preguntas['preguntas_filtradas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(preguntas['preguntas_filtradas'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preguntas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "claves = list(preguntas['preguntas_filtradas'].keys())\n",
    "\n",
    "preguntas_reales_filtradas_pero_reales = list(df_preguntas[df_preguntas['id_pregunta'].iloc[: , 0].isin(claves)]['pregunta_contenido'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "preguntas_reales_filtradas_pero_reales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preguntas['respuesta_contenido']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preguntas[list(df_preguntas[\"pregunta_contenido\"].isin(preguntas_reales_filtradas_pero_reales))]['respuesta_contenido']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_espero_que_definitivo_o_me_cuelgo = {}\n",
    "\n",
    "for pregunta in preguntas_reales_filtradas_pero_reales:\n",
    "\n",
    "     respuestones = df_preguntas[df_preguntas[\"pregunta_contenido\"] == pregunta][\"respuesta_contenido\"].tolist()\n",
    "\n",
    "\n",
    "     dict_espero_que_definitivo_o_me_cuelgo[pregunta] = respuestones\n",
    "\n",
    "dict_espero_que_definitivo_o_me_cuelgo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "preguntas_unicas = df_preguntas[\n",
    "        (df_preguntas['categoria'] == categoria) &\n",
    "        (df_preguntas['usuario'] == tipo_usuario) &\n",
    "        (df_preguntas['activa'] == True)\n",
    "    ][['pregunta_contenido','id_pregunta']].drop_duplicates()\n",
    "lista_preguntas = preguntas_unicas['pregunta_contenido']\n",
    "type(lista_preguntas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "preguntas_unicas = df_preguntas[\n",
    "        (df_preguntas['categoria'] == categoria) &\n",
    "        (df_preguntas['usuario'] == tipo_usuario) &\n",
    "        (df_preguntas['activa'] == True)\n",
    "    ][['pregunta_contenido','id_pregunta']].drop_duplicates()\n",
    "lista_preguntas = preguntas_unicas['pregunta_contenido'].tolist()\n",
    "lista_ids = preguntas_unicas['id_pregunta'].iloc[:,0].tolist()\n",
    "dict_preguntas = {}\n",
    "for i in range(len(lista_preguntas)):\n",
    "    dict_preguntas[lista_ids[i]] = lista_preguntas[i]\n",
    "dict_preguntas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preguntas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pregunta1 = \"¿Has notado algun sintoma desde el diagnostico?\"\n",
    "df_preguntas[df_preguntas[\"pregunta_contenido\"] == pregunta1][\"respuesta_contenido\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preguntas = db_get_questions()\n",
    "df_preguntas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_preg_resp = {}\n",
    "for pregunta in df_preguntas[\"pregunta_contenido\"].drop_duplicates():\n",
    "     resp_list = df_preguntas[df_preguntas[\"pregunta_contenido\"] == pregunta][\"respuesta_contenido\"].tolist()\n",
    "     dict_preg_resp[pregunta] = resp_list\n",
    "dict_preg_resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preguntas_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "listado_preguntas = respuesta['listado_preguntas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_preguntas[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_prueba(id_sesion, categoria):\n",
    "    ### Sacamos contexto del usuario y las preguntas activas, antes de tocar por el LLM.\n",
    "    info_user= db_user_context(id_sesion)\n",
    "    id_respuesta_usuario=info_user['id_respuesta_usuario']\n",
    "    direccion_ip=info_user['direccion_ip']\n",
    "    tipo_usuario=info_user['tipo_usuario']\n",
    "    municipio=info_user['municipio']\n",
    "    ccaa=info_user['ccaa']\n",
    "    conocer_felgtbi=info_user['conocer_felgtbi']\n",
    "    data_date=info_user['data_date']\n",
    "    vih_usuario=info_user['vih_usuario']\n",
    "    vih_diagnostico=info_user['vih_diagnostico']\n",
    "    vih_tratamiento=info_user['vih_tratamiento']\n",
    "    us_edad=info_user['us_edad']\n",
    "    us_pais_origen=info_user['us_pais_origen']\n",
    "    us_genero=info_user['us_genero']\n",
    "    us_orientacion=info_user['us_orientacion']\n",
    "    us_situacion_afectiva=info_user['us_situacion_afectiva']\n",
    "    us_hablado=info_user['us_hablado']\n",
    "    pro_ambito=info_user['pro_ambito']\n",
    "    pro_especialidad=info_user['pro_especialidad']\n",
    "    pro_vih_profesional=info_user['pro_vih_profesional']\n",
    "    locals().update(info_user)\n",
    "    print(id_respuesta_usuario)\n",
    "    print(conocer_felgtbi)\n",
    "    print(us_orientacion)\n",
    "llm_prueba('prueba_raul_limpiador', 'divulgacion')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ENCAPSULO EL LIMPIADOR ÁRBOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diccionario_final_arbol(preguntas):\n",
    "\n",
    "     claves = eval(preguntas)\n",
    "\n",
    "     preguntas_reales_filtradas_pero_reales = list(df_preguntas[df_preguntas['id_pregunta'].iloc[: , 0].isin(claves)]['pregunta_contenido'].unique())\n",
    "\n",
    "     dict_espero_que_definitivo_o_me_cuelgo = {}\n",
    "\n",
    "     for pregunta in preguntas_reales_filtradas_pero_reales:\n",
    "\n",
    "          respuestones = df_preguntas[df_preguntas[\"pregunta_contenido\"] == pregunta][\"respuesta_contenido\"].tolist()\n",
    "\n",
    "          dict_espero_que_definitivo_o_me_cuelgo[pregunta] = respuestones\n",
    "\n",
    "     return dict_espero_que_definitivo_o_me_cuelgo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Ejemplo de Álex\n",
    "def llm_limpiador(id_sesion, categoria):\n",
    "     # Obtener contexto del usuario\n",
    "     info_user = db_user_context(id_sesion)\n",
    "     tipo_usuario = info_user['tipo_usuario']\n",
    "     municipio = info_user['municipio']\n",
    "     ccaa = info_user['ccaa']\n",
    "     vih_usuario = info_user['vih_usuario']\n",
    "     us_edad = info_user['us_edad']\n",
    "     us_pais_origen = info_user['us_pais_origen']\n",
    "     us_genero = info_user['us_genero']\n",
    "     us_orientacion = info_user['us_orientacion']\n",
    "     us_situacion_afectiva = info_user['us_situacion_afectiva']\n",
    "     us_hablado = info_user['us_hablado']\n",
    "     pro_ambito = info_user['pro_ambito']\n",
    "     pro_especialidad = info_user['pro_especialidad']\n",
    "     pro_vih_profesional = info_user['pro_vih_profesional']\n",
    "\n",
    "     # Obtener preguntas activas\n",
    "     df_preguntas = db_get_questions()\n",
    "     preguntas_unicas = df_preguntas[\n",
    "          (df_preguntas['categoria'] == categoria) &\n",
    "          (df_preguntas['usuario'] == tipo_usuario) &\n",
    "          (df_preguntas['activa'] == True)\n",
    "     ][['pregunta_contenido','id_pregunta']].drop_duplicates()\n",
    "     lista_preguntas = preguntas_unicas['pregunta_contenido'].tolist()\n",
    "     lista_ids = preguntas_unicas['id_pregunta'].iloc[:,0].tolist()\n",
    "     dict_preguntas = {}\n",
    "     for i in range(len(lista_preguntas)):\n",
    "          dict_preguntas[lista_ids[i]] = lista_preguntas[i]\n",
    "     dict_preguntas\n",
    "\n",
    "     # Configuración del LLM\n",
    "     cohere_api_key = os.getenv(\"COHERE_TRIAL_API_KEY\")\n",
    "     llm = ChatCohere(cohere_api_key=cohere_api_key, temperature=0, model='command-r-plus')\n",
    "\n",
    "     # Template del prompt\n",
    "     prompt = f\"\"\"\n",
    "     Recibes un diccionario de preguntas: {dict_preguntas}. La clave es el ID de la pregunta, y el valor es el texto de la pregunta.\n",
    "     Tu tarea es filtrar las preguntas de acuerdo con el contexto del usuario, siguiendo las siguientes reglas:\n",
    "\n",
    "     1. **Filtrado por vih**:\n",
    "     - Si el usuario **NO** tiene vih, elimina todas las preguntas relacionadas con padecer dicha enfermedad y pasas al filtrado de género.\n",
    "\n",
    "     - Si el usuario **SI** tiene vih, lanzas las preguntas relacionadas con padecer dicha enfermedad y pasas al filtrado de género.\n",
    "\n",
    "     2. **Filtrado por género**:\n",
    "\n",
    "          - **Género masculino**: Si el género del usuario es **masculino**, elimina preguntas que no sean relevantes para este género. Por ejemplo, si una pregunta está relacionada con aspectos específicos de la biología femenina (como embarazo, periodo, etc), elimínala. Es decir, solo mantén preguntas que sean pertinentes a la biología o situaciones de los hombres.\n",
    "\n",
    "          - **Género femenino**: Si el género del usuario es **femenino**, elimina preguntas que no sean relevantes para este género. Por ejemplo, si una pregunta está relacionada con aspectos específicos de la biología masculina (como próstata), elimínala. Es decir, solo mantén preguntas que sean pertinentes a la biología o situaciones de las mujeres.\n",
    "\n",
    "          - **Género no binario**: Si el género del usuario es **no binario**, elimina preguntas que se refieran de manera exclusiva a biología o situaciones de los géneros masculinos o femeninos. Este género no se asocia con los aspectos tradicionales de los géneros binarios, por lo que solo se deben incluir preguntas de carácter general o que no dependan del género biológico.\n",
    "\n",
    "          - **Prefiero no decirlo**: Si el usuario seleccionó **prefiero no decirlo** como género, elimina preguntas que estén asociadas con un género específico, ya que no se puede asumir el género del usuario. Solo incluye preguntas que no dependan de un género específico.\n",
    "\n",
    "     **Importante**: No modifiques el texto de las preguntas. Solo elimina las preguntas según las reglas mencionadas. Nunca debes modificar el contenido de las preguntas, solo eliminarlas si no son relevantes según el contexto.\n",
    "\n",
    "     **Importante**: No escribirás VIH en mayúsculas en ningún caso ya que estamos desestigmatizando dicha enfermedad.\n",
    "\n",
    "     Información del usuario:\n",
    "     Tipo: {tipo_usuario}, Municipio: {municipio}, CCAA: {ccaa}, Edad: {us_edad}, País de origen: {us_pais_origen},\n",
    "     Género: {us_genero}, Orientación: {us_orientacion}, Situación afectiva: {us_situacion_afectiva}, Ha hablado sobre vih: {us_hablado},\n",
    "     Tiene vih: {vih_usuario}, Profesional (ámbito: {pro_ambito}, especialidad: {pro_especialidad}, experiencia con vih: {pro_vih_profesional}).\n",
    "\n",
    "     **Salida Esperada:**\n",
    "     Devuelve única y exclusivamente una lista de Python con los ID de las preguntas filtradas seleccionadas. No debes devolver nada más, Solo una lista con los ID seleccionados.\n",
    "\n",
    "          - **Ejemplo 1** [1, 4, 7]\n",
    "          - **Ejemplo 2** [1, 3, 6, 8, 9]\n",
    "     \"\"\"\n",
    "\n",
    "     # Invocar el modelo\n",
    "     response = llm.invoke(prompt)\n",
    "     # print(\"Respuesta del modelo:\", response.content)\n",
    "\n",
    "\n",
    "     return diccionario_final_arbol(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_limpiador('prueba_raul_limpiador', 'divulgacion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruebas encapsulamiento funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import llm_limpiador, db_user_interaction, db_user_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\raulg\\Documents\\THEBRIDGE_DS\\0.-Repo_Git\\Desafio-Final\\model.py:287: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  preguntas = pd.read_sql(query,conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<cursor object at 0x00000244A8C718C0; closed: 0>\n",
      "<cursor object at 0x00000244A8C73BC0; closed: 0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\raulg\\Documents\\THEBRIDGE_DS\\0.-Repo_Git\\Desafio-Final\\model.py:287: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  preguntas = pd.read_sql(query,conn)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'¿Cuál es tu color favorito?': ['Rojo', 'Azul', 'Otro color'],\n",
       " '¿Las relaciones que mantuviste fueron con proteccion?': ['No', 'Si'],\n",
       " '¿Has notado síntomas desde que te diagnosticaron vih?': ['Si', 'No']}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_limpiador('prueba_raul_limpiador')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_sesion = 'prueba_raul_limpiador'\n",
    "categoria_pregunta = 'divulgacion'\n",
    "preguntas_limpias = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preguntas ya recogidas\n"
     ]
    }
   ],
   "source": [
    "if len(preguntas_limpias) == 0:\n",
    "    print(\"Recogiendo preguntas...\")\n",
    "    preguntas_limpias = llm_limpiador(id_sesion)\n",
    "    print(len(preguntas_limpias))\n",
    "else:\n",
    "    print(\"Preguntas ya recogidas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'¿Cuál es tu color favorito?': ['Rojo', 'Azul', 'Otro color'],\n",
       " '¿Las relaciones que mantuviste fueron con proteccion?': ['No', 'Si'],\n",
       " '¿Has notado síntomas desde que te diagnosticaron vih?': ['Si', 'No']}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preguntas_limpias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_user_interaction(\"prueba_raul_limpiador\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_user_context(\"prueba_raul_limpiador\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
